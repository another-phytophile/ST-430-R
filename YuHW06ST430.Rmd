---
title: "Hw06ST430Yu"
author: "Haozhe (Jerry) Yu"
date: "`r Sys.Date()`"
output: 
  pdf_document:
    latex_engine: xelatex
---

```{r setup, include=FALSE}
library(tidyverse)
library(ggpmisc)
library(dplyr)
library(tidyverse)
library(tinytex)
library(usethis)
library(lmtest)
library(car)
library(rsq)
library(leaps)
ftest = function(model, L, h = 0)
  # General linear test of H0: L beta = h
{
  BetaHat = model$coefficients
  dimL = dim(L)
  if (length(BetaHat) != dimL[2])
    stop("Sizes of L and Beta are incompatible")
  r = dimL[1]
  if (qr(L)$rank != r)
    stop("Rows of L must be linearly independent.")
  out = numeric(4)
  names(out) = c("F", "df1", "df2", "p-value")
  dfe = df.residual(model)
  diff = L %*% BetaHat - h
  fstat = t(diff) %*% solve(L %*% vcov(model) %*% t(L)) %*% diff / r
  # Note vcov = MSE * XtXinv
  fstat = as.numeric(fstat)
  out[1] = fstat
  out[2] = r
  out[3] = dfe
  out[4] = 1 - pf(fstat, r, dfe)
  return(out)
} # End of function ftest
```

# Question 1

A researcher studied the effects of the charge rate and temperature on the life of a new type of power cell in a preliminary small-scale experiment. The charge rate (Xl) was controlled at three levels (0.6, 1.0, and 1.4 amperes) and the ambient temperature (X2) was controlled at three levels (l0, 20, 30Â°C). Factors pertaining to the discharge of the power cell were held at fixed levels. The life of the power cell (Y) was measured in terms of the number of discharge-charge cycles that a power cell underwent before it failed.

The researcher was not sure about the nature of the response function in the range of the factors studied. Hence, the researcher decided to fit the second-order polynomial regression model

```{r import1}
data <- read.table("Datasets/battery.txt", header=FALSE)
names(data) <- c("cycles","rate","temp")
attach(data)
```

##a.	Find the correlation matrix and report any high correlation between predictor variables.

```{r cor1}
cor(data)
```
The correlation between cycles and temp is 0.7512159. This is high and could be a sign of multicollinearity. 

##b.	Fit a full model (Shown above) and report the overall F value and individual t-values. Do you suspect any multicollinearity problem?


```{r fmod}
mod1<-lm(cycles~rate+temp+I(rate^2)+I(temp^2)+ I(rate*temp))
summary(mod1)
```
Yes I do. The overall p value for the ANOVA is < 0.05, but each of the individual regression coefficient's p values are more than 0.05. This is a sign of multicollinearity. Additionaly, this is a polynomial regression that has not been centered so by definition it will have structural multicollinearity. 

## c.	We can remove the high correlation between explanatory variables and their powers by centering. 

```{r ccor1}
rate.code <- (rate-mean(rate))/0.4
temp.code <- (temp-mean(temp))/10
cor(cbind(rate.code,temp.code,rate.code^2,temp.code^2))
```
In this new correlation matrix I do not obervs any high correlations and therefore signs of multicollinearity. 

## d.Fit a new full model with the scaled new predictor variables and report the estimated regression function

```{r cmod1}
mod2<-lm(cycles~rate.code+temp.code+I(rate.code^2)+I(temp.code^2)+I(rate.code*temp.code))
summary(mod2)

summary(mod2)$coeff[1,1]
```
Cycles = `r summary(mod2)$coeff[1,1]` + `r summary(mod2)$coeff[2,1]`rate.code + `r summary(mod2)$coeff[3,1]`temp.code + `r summary(mod2)$coeff[4,1]`rate.code^2 + `r summary(mod2)$coeff[5,1]`temp.code^2 + `r summary(mod2)$coeff[6,1]`[rate.code * temp.code]
